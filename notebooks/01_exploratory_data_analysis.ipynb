{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import importlib\n",
    "propject_root = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..'))\n",
    "sys.path.append(propject_root)\n",
    "\n",
    "\n",
    "import src.database.redshift_connection as redshift_connection\n",
    "import src.plotly_wrapper.scatter as sc_wrapper\n",
    "import src.plotly_wrapper.box as box_wrapper\n",
    "import src.plotly_wrapper.bar as bar_wrapper\n",
    "import src.plotly_wrapper.figure as fig_wrapper\n",
    "import src.plotly_wrapper.trace as tc\n",
    "import src.utils.calendar_utils as cu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = redshift_connection.RedshiftConnection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(read_from_file=False, conn=None):\n",
    "    if read_from_file:\n",
    "        results = pd.read_csv('/Users/ahmed.sobih/recon_results.csv').drop_duplicates()\n",
    "    else:\n",
    "        f = open('../sql/queries/raw_records.sql', 'r')\n",
    "        try:\n",
    "            query = f.read()\n",
    "        finally:\n",
    "            f.close()\n",
    "        results = conn.execute_query(query)\n",
    "    return results\n",
    "# results = get_results(read_from_file=False, conn=conn)\n",
    "\n",
    "results = get_results(read_from_file=True, conn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Records per city count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_records_per_city(results):\n",
    "    importlib.reload(bar_wrapper)\n",
    "    importlib.reload(fig_wrapper)\n",
    "\n",
    "    num_records_per_city = results.groupby('city').agg(\n",
    "        num_records = ('remittance', 'size')\n",
    "    ).reset_index().sort_values(by='num_records', ascending=False)\n",
    "    num_records_per_city['num_records'] = num_records_per_city['num_records'].astype(int)\n",
    "    num_records_per_city['percent_of_total_text'] = np.round(num_records_per_city['num_records']/len(results)*100, 1).astype(str) + '%'\n",
    "    num_records_per_city['num_records_text'] = np.round(num_records_per_city['num_records']/1000000, 2).astype(str) + 'M'\n",
    "    bar = bar_wrapper.Bar(\n",
    "        df=num_records_per_city,\n",
    "        x_col='city',\n",
    "        y_col='num_records',\n",
    "        name='', \n",
    "        text=list(num_records_per_city.percent_of_total_text)\n",
    "    )\n",
    "    fig = fig_wrapper.Figure([bar], None, 'Number of records per city')\n",
    "    fig.set_axis_title(xaxis_title='City', yaxis_title='Number of records')\n",
    "    fig.show_legend=False\n",
    "    fig.show()\n",
    "    fig.save('records_per_city.jpg')\n",
    "\n",
    "plot_records_per_city(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero and NULL value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_remittance_net_earnings_stats(results):\n",
    "    rec_per_city = results.groupby('city').agg(\n",
    "        num_records = ('remittance', 'size'),  \n",
    "        percent_of_total = ('remittance', lambda x: np.round(len(x)/len(results), 2)),\n",
    "        zero_remittance_percentage = ('remittance', lambda x: np.round(len(x[x==0])/len(x), 2)),\n",
    "        null_remittance_percentage = ('remittance', lambda x: np.round(len(x[x.isnull()])/len(x), 2)), \n",
    "        zero_net_earning_percentage = ('net_earning', lambda x: np.round(len(x[x==0])/len(x), 2)),\n",
    "        null_net_earning_percentage = ('net_earning', lambda x: np.round(len(x[x.isnull()])/len(x), 2)),\n",
    "    ).reset_index().sort_values(by='zero_remittance_percentage', ascending=False)\n",
    "\n",
    "    rec_per_city['zero_remittance_percentage'] = rec_per_city['zero_remittance_percentage'].astype(float)\n",
    "    rec_per_city['null_remittance_percentage'] = rec_per_city['null_remittance_percentage'].astype(float)\n",
    "    rec_per_city['num_records'] = rec_per_city['num_records'].astype(int)\n",
    "    rec_per_city.sort_values(by='num_records', ascending=False)\n",
    "    return rec_per_city\n",
    "get_remittance_net_earnings_stats(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percenate of zero remittance: ' , np.round(len(results[(results.remittance==0)])/len(results), 2)*100)\n",
    "print('Percenate of zero net_earning: ' , np.round(len(results[(results.net_earning==0)])/len(results), 2)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remittance and Net earnings Percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dataframe with the quantiles of the remittance and net_earning for each city\n",
    "def create_quantiles_df(results, col='remittance'):\n",
    "    quantiles = results.groupby('city')[col].quantile(np.arange(0, 1.01, 0.01)).reset_index()\n",
    "    quantiles.rename(columns={'level_1': 'quantile', col: f'{col}_value'}, inplace=True)\n",
    "    pivot_quantiles = quantiles.pivot(\n",
    "        index='quantile', \n",
    "        columns='city', \n",
    "        values=f'{col}_value'\n",
    "    ).reset_index()\n",
    "    pivot_quantiles = pivot_quantiles[['quantile', 'Lagos', 'Accra', 'Johannesburg', 'Cape Town', \n",
    "                            'Nairobi', 'Ibadan', 'mumbai', 'bangalore', 'hyderabad']]\n",
    "    pivot_quantiles.to_csv(f'../data/processed/{col}_quantiles.csv', index=False)\n",
    "    \n",
    "    return pivot_quantiles\n",
    "create_quantiles_df(results, col='remittance')\n",
    "create_quantiles_df(results, col='net_earning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_value_range(results, col='remittance'):\n",
    "    importlib.reload(fig_wrapper)\n",
    "    importlib.reload(box_wrapper)\n",
    "\n",
    "    results_with_quantiles = results.merge(\n",
    "        results.groupby('city')[col].quantile(0.98).reset_index().rename(\n",
    "            columns={col: f'{col}_98'}\n",
    "        ), on='city', how='left'\n",
    "    ).merge(\n",
    "        results.groupby('city')[col].quantile(0.01).reset_index().rename(\n",
    "            columns={col: f'{col}_01'}\n",
    "        ), on='city', how='left'\n",
    "    )\n",
    "    plot_data = results_with_quantiles[\n",
    "                (results_with_quantiles[col] <= results_with_quantiles[f'{col}_98']) & \n",
    "                (results_with_quantiles[col] >= results_with_quantiles[f'{col}_01']) & \n",
    "                (results_with_quantiles[col] != 0)\n",
    "            ]\n",
    "    box = box_wrapper.Box(\n",
    "        df= plot_data, \n",
    "        x_col='city',\n",
    "        y_col=col,\n",
    "        legendgrouptitle='City',\n",
    "        name='', boxpoints=False\n",
    "    )\n",
    "\n",
    "    title = f'{col.replace(\"_\", \" \").capitalize()} Value Range'\n",
    "    \n",
    "    fig = fig_wrapper.Figure([box], None, title)\n",
    "\n",
    "    for city in results_with_quantiles.city.unique():\n",
    "        median_value = plot_data[plot_data.city==city][col].median()\n",
    "        y = plot_data[plot_data.city==city][col].max()\n",
    "        fig.add_annotation(\n",
    "            x=city,\n",
    "            y=y+1500,\n",
    "            text=f'{np.round(median_value/1000, 1)}k',\n",
    "            showarrow=False\n",
    "        )\n",
    "    fig.set_axis_title(xaxis_title='City', yaxis_title=title)\n",
    "    fig.show()\n",
    "    fig.show_legend=False\n",
    "    fig.save(f'{col}_value_range.jpg')\n",
    "\n",
    "plot_value_range(results, col='remittance')\n",
    "plot_value_range(results, col='net_earning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekly Insights\n",
    "### Create Weekly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_results(results, filter_zero_remittance=True, filter_zero_net_earning=True):\n",
    "    filtered_results = results[\n",
    "        (~results.drn.isnull()) &\n",
    "        (~results.city.isnull()) & \n",
    "        (~results.week.isnull()) & \n",
    "        (results.week <= '2025-03-10')\n",
    "    ].drop_duplicates()\n",
    "    if filter_zero_remittance:\n",
    "        filtered_results = filtered_results[filtered_results.remittance > 0]\n",
    "    if filter_zero_net_earning:\n",
    "        filtered_results = filtered_results[filtered_results.net_earning > 0]\n",
    "    col = 'remittance'\n",
    "    filtered_results = filtered_results.merge(\n",
    "            results.groupby('city')[col].quantile(0.98).reset_index().rename(\n",
    "                columns={col: f'{col}_98'}\n",
    "            ), on='city', how='left'\n",
    "        ).merge(\n",
    "            results.groupby('city')[col].quantile(0.01).reset_index().rename(\n",
    "                columns={col: f'{col}_01'}\n",
    "            ), on='city', how='left'\n",
    "        )\n",
    "    \n",
    "    return filtered_results\n",
    "\n",
    "def get_weekly_results(filtered_results):\n",
    "    filtered_results = get_filtered_results(results)\n",
    "    weekly_agg = filtered_results.groupby(['city', 'drn', 'week']).agg(\n",
    "        remittance = ('remittance', 'sum'),\n",
    "        net_earning = ('net_earning', 'sum'),\n",
    "        num_records = ('remittance', 'size'),\n",
    "    ).reset_index()\n",
    "    \n",
    "    weekly_agg['week'] = pd.to_datetime(weekly_agg['week'])\n",
    "    \n",
    "    weekly_agg['week_num']= weekly_agg.sort_values(\n",
    "        ['city', 'drn', 'week'], ascending=True\n",
    "    ).groupby(['city', 'drn']).cumcount()\n",
    "\n",
    "    weekly_agg['is_remittance_paid'] = np.where(\n",
    "        weekly_agg.remittance <= weekly_agg.net_earning, \n",
    "        1, \n",
    "        0\n",
    "    )\n",
    "    first_week = weekly_agg.groupby(['city', 'drn']).agg(\n",
    "        first_week = ('week', 'min'),\n",
    "    ).reset_index()\n",
    "    weekly_agg = weekly_agg.merge(first_week, on=['city', 'drn'], how='left')\n",
    "    weekly_agg['first_month'] = weekly_agg.first_week.dt.to_period('M').dt.end_time\n",
    "\n",
    "    #weekly_agg['week_num'] = weekly_agg.sort_values(['city', 'drn', 'week']).groupby(['city', 'drn']).cumcount()\n",
    "    return weekly_agg\n",
    "\n",
    "weekly_agg = get_weekly_results(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_agg.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weeks_calendar(weekly_agg):\n",
    "    weeks = weekly_agg[['week']].drop_duplicates()\n",
    "\n",
    "    importlib.reload(cu)\n",
    "\n",
    "    calendar = cu.create_week_calendar(\n",
    "        start_date='2020-01-01',\n",
    "        end_date=weekly_agg.week.max().strftime('%Y-%m-%d')\n",
    "    )\n",
    "    weeks = weeks.merge(\n",
    "        calendar, left_on='week', \n",
    "        right_on = 'week_start', \n",
    "        how='left'\n",
    "    ).sort_values(by='week_start')\n",
    "    \n",
    "    wrong_week_tag = weekly_agg[\n",
    "        weekly_agg.week.isin(\n",
    "            weeks[weeks.week_start.isnull()].week\n",
    "        )\n",
    "    ].groupby(['city', 'week']).agg(\n",
    "        num_records = ('remittance', 'size'),\n",
    "    ).reset_index()\n",
    "    wrong_week_tag.to_csv('../data/processed/wrong_week_tag.csv', index=False)\n",
    "    return weeks[~weeks.week_start.isnull()]\n",
    "\n",
    "\n",
    "def get_city_week_results(weekly_agg, groupby_columns=['city', 'week']):\n",
    "    city_week_results = weekly_agg.groupby(groupby_columns).agg(\n",
    "        num_records = ('remittance', 'size'),\n",
    "        remittance = ('is_remittance_paid', 'sum'),\n",
    "    ).reset_index()\n",
    "    city_week_results['is_remittance_paid_percentage'] = city_week_results['remittance']/city_week_results['num_records']\n",
    "    \n",
    "    weeks = get_weeks_calendar(weekly_agg)\n",
    "    if 'city' in groupby_columns:\n",
    "    # Create a dataframe is a product of weeks and cities\n",
    "        import itertools\n",
    "        weeks_cities = pd.DataFrame(\n",
    "            list(itertools.product(weeks.week, weekly_agg.city.unique())),\n",
    "            columns=['week', 'city'] \n",
    "        )\n",
    "    else:\n",
    "        weeks_cities = weeks\n",
    "    city_week_results = weeks_cities.merge(\n",
    "        city_week_results,\n",
    "        on=groupby_columns,\n",
    "        how='left'\n",
    "    ).sort_values(by=groupby_columns, ascending=True)\n",
    "    city_week_results['num_records'] = city_week_results['num_records'].fillna(0)\n",
    "    city_week_results['remittance'] = city_week_results['remittance'].fillna(0)\n",
    "    if 'city' in groupby_columns:\n",
    "        city_start_date = city_week_results[city_week_results.num_records>0].groupby('city').agg(\n",
    "            start_date = ('week', 'min')\n",
    "        ).reset_index()\n",
    "        city_week_results = city_week_results.merge(\n",
    "            city_start_date,\n",
    "            on='city',\n",
    "            how='left'\n",
    "        )   \n",
    "        city_week_results = city_week_results[city_week_results.week>=city_week_results.start_date]\n",
    "    city_week_results['is_remittance_paid_percentage'] = city_week_results['is_remittance_paid_percentage'].fillna(0)\n",
    "    return city_week_results\n",
    "\n",
    "city_week_results = get_city_week_results(weekly_agg)\n",
    "all_results = get_city_week_results(weekly_agg, groupby_columns=['week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weekly_stats(results, y_col='num_records'):\n",
    "    importlib.reload(fig_wrapper)\n",
    "    importlib.reload(sc_wrapper)\n",
    "    traces= []\n",
    "    \n",
    "    file_name = f'weekly_{y_col}'\n",
    "    if y_col == 'num_records':\n",
    "        title = f'Weekly # of remittance records'\n",
    "        yaxis_title= '# of records'\n",
    "    elif y_col == 'is_remittance_paid_percentage':\n",
    "        title = f'Weekly % of remittance fully covered'\n",
    "        yaxis_title= '% of remittance fully covered'\n",
    "    else:\n",
    "        title = f'Weekly {y_col.replace(\"_\", \" \")}'\n",
    "        yaxis_title= y_col.replace(\"_\", \" \").capitalize()\n",
    "        \n",
    "    if 'city' in results.columns:\n",
    "        for city in results.city.unique(): \n",
    "            scatter = sc_wrapper.Scatter(\n",
    "                df= results[results.city==city], \n",
    "                x_col='week',\n",
    "                y_col=y_col,\n",
    "                mode='lines',\n",
    "                legendgrouptitle='City',\n",
    "                name=city\n",
    "            )\n",
    "            traces.append(scatter)\n",
    "        file_name = f'city_{file_name}'\n",
    "        title = f'{title} per city'  \n",
    "    else:\n",
    "        scatter = sc_wrapper.Scatter(\n",
    "            df= results, \n",
    "            x_col='week',\n",
    "            y_col=y_col,\n",
    "            mode='lines',\n",
    "            name=''\n",
    "        )\n",
    "        traces.append(scatter)\n",
    "\n",
    "    \n",
    "    fig = fig_wrapper.Figure(traces, None, title)\n",
    "    fig.set_axis_title(xaxis_title='Week', yaxis_title=yaxis_title)\n",
    "    if not 'city' in results.columns:\n",
    "        fig.show_legend=False\n",
    "    if y_col=='is_remittance_paid_percentage':\n",
    "        fig.set_percentage_axis()\n",
    "    fig.show()\n",
    "    fig.save(file_name + '.jpg')\n",
    "\n",
    "plot_weekly_stats(results = city_week_results, y_col='num_records')\n",
    "plot_weekly_stats(results = all_results, y_col='num_records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weekly_stats(results = city_week_results, y_col='is_remittance_paid_percentage')\n",
    "plot_weekly_stats(results = all_results, y_col='is_remittance_paid_percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drn_stats(results_agg):\n",
    "    results_agg_copy = results_agg.copy(deep=True)\n",
    "   \n",
    "    weeks = get_weeks_calendar(results_agg)\n",
    "    import itertools\n",
    "    city_drn = results_agg[['city', 'drn']].drop_duplicates()\n",
    "    city_drn['tmp_col'] = 1\n",
    "    weeks['tmp_col'] = 1\n",
    "    weeks_city_drn = city_drn.merge(weeks, on='tmp_col', how='left')\n",
    "    del city_drn['tmp_col']\n",
    "    # weeks_city_drn = pd.DataFrame(\n",
    "    #     list(itertools.product(weeks.week, weekly_agg.drn.unique())),\n",
    "    #     columns=['week', 'drn'] \n",
    "    # )\n",
    "    drn_stats = weeks_city_drn.merge(\n",
    "        results_agg_copy, \n",
    "        on=['city', 'week', 'drn'], \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    drn_start_date = drn_stats[drn_stats.num_records>0].groupby(['city', 'drn']).agg(\n",
    "        start_date = ('week', 'min')\n",
    "    ).reset_index()\n",
    "    drn_stats = drn_stats.merge(drn_start_date, on=['city', 'drn'], how='left')\n",
    "    drn_stats = drn_stats[drn_stats.week>=drn_stats.start_date]\n",
    "    drn_stats['week_num'] = drn_stats.sort_values(\n",
    "        ['city', 'drn', 'week'], ascending=True\n",
    "    ).groupby(['city', 'drn']).cumcount()\n",
    "    \n",
    "    drn_stats['month'] = drn_stats.week.dt.to_period('M')\n",
    "    return drn_stats\n",
    "drn_stats = get_drn_stats(weekly_agg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drn_month_cohorts(drn_stats):\n",
    "    drn_month_cohorts = drn_stats.groupby(['first_month']).agg(\n",
    "        num_drns = ('drn', 'nunique')\n",
    "    ).reset_index()\n",
    "    return drn_month_cohorts\n",
    "\n",
    "def plot_drn_month_cohorts(drn_stats):\n",
    "    importlib.reload(fig_wrapper)\n",
    "    importlib.reload(sc_wrapper)\n",
    "    drn_month_cohorts = get_drn_month_cohorts(drn_stats)\n",
    "    traces= []\n",
    "    scatter = sc_wrapper.Scatter(\n",
    "            df= drn_month_cohorts, \n",
    "            x_col='first_month',\n",
    "            y_col='num_drns',\n",
    "            mode='lines',\n",
    "            legendgrouptitle='City',\n",
    "            name=f''\n",
    "        )\n",
    "    traces.append(scatter)\n",
    "    fig = fig_wrapper.Figure(traces, None, title=f'Cohort size overtime')\n",
    "    fig.set_axis_title(xaxis_title='Month', yaxis_title='Cohort size')\n",
    "    fig.show_legend=False\n",
    "    fig.show()\n",
    "    fig.save('drn_month_cohorts.jpg')\n",
    "plot_drn_month_cohorts(drn_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cohort_heatmap(drn_stats):\n",
    "    drn_month_cohorts= get_drn_month_cohorts(drn_stats)\n",
    "    drn_month_cohorts = drn_month_cohorts.merge(\n",
    "        drn_stats.groupby(['first_month', 'week']).agg(\n",
    "            paid_remittance = ('is_remittance_paid', 'sum'),\n",
    "        ).reset_index(),\n",
    "        on=['first_month'],\n",
    "        how='left'\n",
    "    ).sort_values(by=['first_month', 'week'], ascending=True)\n",
    "    drn_month_cohorts['is_remittance_paid_percentage'] = drn_month_cohorts['paid_remittance']/drn_month_cohorts['num_drns']\n",
    "\n",
    "\n",
    "    cohort_pivot= drn_month_cohorts.pivot(\n",
    "        index='first_month', \n",
    "        columns='week', \n",
    "        values='is_remittance_paid_percentage'\n",
    "    )\n",
    "\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=go.Heatmap(\n",
    "        z=cohort_pivot,\n",
    "        x=cohort_pivot.columns,\n",
    "        y=cohort_pivot.index,\n",
    "        colorscale='YlGn',  # Built-in color scale\n",
    "    ))\n",
    "    default_layout = fig_wrapper.Figure([], None, 'Cohort % of remittance paid')._default_layout()\n",
    "    default_layout['xaxis']['title']['text'] = 'Week #'\n",
    "    default_layout['yaxis']['title']['text'] = 'Cohort Month'\n",
    "    default_layout['yaxis']['autorange'] = 'reversed'\n",
    "    fig.layout= default_layout\n",
    "    fig.show()\n",
    "    fig.write_image(\n",
    "        \"../reports/plots/\" + 'cohort_analysis_heatmap.jpg', \n",
    "        format=\"jpeg\",\n",
    "        width=600, \n",
    "        height=400, \n",
    "        scale=6,\n",
    "        engine=\"kaleido\"\n",
    "    )\n",
    "\n",
    "plot_cohort_heatmap(drn_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vitalik Query Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vitlik_data(file_name='../data/processed/vitalik_query_results.csv'):\n",
    "    importlib.reload(fig_wrapper)\n",
    "    importlib.reload(sc_wrapper)\n",
    "    if file_name is not None:\n",
    "        test_results = pd.read_csv(file_name)\n",
    "    else:\n",
    "        f = open('../sql/queries/vitalik_query.sql', 'r')\n",
    "        try:\n",
    "            query = f.read()\n",
    "        finally:\n",
    "            f.close()\n",
    "        test_results = conn.execute_query(query)\n",
    "        test_results.to_csv('../data/processed/vitalik_query_results.csv', index=False)\n",
    "    traces=[]\n",
    "    for country in test_results.country.unique():\n",
    "        scatter = sc_wrapper.Scatter(\n",
    "                    df= test_results[test_results.country==country], \n",
    "                    x_col='week',\n",
    "                    y_col='pct_drivers_earning_more_than_remittance',\n",
    "                    mode='lines',\n",
    "                    legendgrouptitle='City',\n",
    "                    name=country\n",
    "                )\n",
    "        traces.append(scatter)\n",
    "    fig = fig_wrapper.Figure(traces, None, title='test')\n",
    "    fig.set_axis_title(xaxis_title='Week', yaxis_title='yaxis_title')\n",
    "    fig.show()\n",
    "        \n",
    "run_vitlik_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
